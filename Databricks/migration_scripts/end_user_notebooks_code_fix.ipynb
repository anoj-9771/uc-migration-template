{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3355a45f-a066-4113-a9c2-a4de9051c043",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h3> Run sheet for end user notebooks code refactoring.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dc5a800-0e88-48f5-960b-d57e8f8dd3ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, re, fnmatch\n",
    "import pandas as pd\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61f60dc9-0ba0-45fe-ba9f-b69cd9e8dea7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#update env parameter and run for various environments\n",
    "env = \"dev_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "438f616c-69fb-4be9-85e3-138f749ad126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# os.mkdir(f\"./user_notebooks/{env.strip('_')}/zips/\")\n",
    "# os.mkdir(f\"./user_notebooks/{env.strip('_')}/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feb1fa81-7c77-4a23-9d26-305ce619ac89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prep folders for pulling end user notebooks\n",
    "try:    \n",
    "    os.mkdir(f\"./user_notebooks/{env.strip('_')}/\")\n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95331db9-3115-4d9e-b522-284ea4e838a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Update the parameter to correct env in \"pull_enduser_files.py\" and execute the script to extract all the files from end user workspace folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e4acccb-6f97-458e-86d8-a849796d6a7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_raw_strings_to_replace(full_path):\n",
    "    \"\"\"get list of strings in codebase that contains 'raw.' (to be later replaced with newer namepsace)\"\"\"\n",
    "    global strings_to_replace\n",
    "    pattern = re.compile(r\"\\braw\\.\\b\")\n",
    "    try:\n",
    "        for filename in os.listdir(full_path):\n",
    "            if filename.endswith(\".py\") or filename.endswith(\".sql\"):\n",
    "                with open(os.path.join(full_path, filename), \"r\") as f:\n",
    "                    for line in f:\n",
    "                        for word in line.split():\n",
    "                            if pattern.search(word): \n",
    "                                if (len(word.split(\".\"))) == 2:\n",
    "                                    strings_to_replace.append( re.sub( r'[)\"](.*)', '', (re.sub('[^A-Za-z0-9.]+_', '', word)) ) )\n",
    "                                else:\n",
    "                                    print (f\"This was formatted poorly and is hence not included in the list:\\n {word}\\n\")\n",
    "            elif os.path.isdir(os.path.join(full_path, filename)) and 'Trash' not in filename:\n",
    "                get_raw_strings_to_replace(os.path.join(full_path, filename))\n",
    "            else:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ee54cd-9f7c-4cf7-a662-a7039cb2d67b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_cleansed_strings_to_replace(full_path):\n",
    "    \"\"\"get list of strings in codebase that contains 'cleansed.' (to be later replaced with newer namepsace)\"\"\"\n",
    "    global strings_to_replace\n",
    "    pattern = re.compile(r\"\\bcleansed\\.\\b\")\n",
    "    try:\n",
    "        for filename in os.listdir(full_path):\n",
    "            if filename.endswith(\".py\") or filename.endswith(\".sql\"):\n",
    "                with open(os.path.join(full_path, filename), \"r\") as f:\n",
    "                    for line in f:\n",
    "                        for word in line.split():\n",
    "                            if pattern.search(word): \n",
    "                                print (word)\n",
    "                                print (full_path, filename)\n",
    "                                if (len(word.split(\".\"))) == 2:\n",
    "                                    strings_to_replace.append( re.sub( r'[)\"](.*)', '', (re.sub('[^A-Za-z0-9.]+_', '', word)) ) )\n",
    "                                else:\n",
    "                                    print (f\"This was formatted poorly and is hence not included in the list:\\n {word}\\n\")\n",
    "            elif os.path.isdir(os.path.join(full_path, filename)) and 'Trash' not in filename:\n",
    "                get_cleansed_strings_to_replace(os.path.join(full_path, filename))\n",
    "            else:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24c09552-ff68-403c-9537-54ee9f524087",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_semantic_strings_to_replace(full_path):\n",
    "    \"\"\"get list of strings in codebase that contains 'semantic.' (to be later replaced with newer namepsace)\"\"\"\n",
    "    global strings_to_replace\n",
    "    pattern = re.compile(r\"\\bsemantic\\.\\b\")\n",
    "    try:\n",
    "        for filename in os.listdir(full_path):\n",
    "            if filename.endswith(\".py\") or filename.endswith(\".sql\"):\n",
    "                with open(os.path.join(full_path, filename), \"r\") as f:\n",
    "                    for line in f:\n",
    "                        for word in line.split():\n",
    "                            if pattern.search(word): \n",
    "                                if (len(word.split(\".\"))) == 2:\n",
    "                                    strings_to_replace.append( re.sub( r'[)\"](.*)', '', (re.sub('[^A-Za-z0-9.]+_', '', word)) ) )\n",
    "                                else:\n",
    "                                    print (f\"This was formatted poorly and is hence not included in the list:\\n {word}\\n\")\n",
    "            elif os.path.isdir(os.path.join(full_path, filename)) and 'Trash' not in filename:\n",
    "                get_semantic_strings_to_replace(os.path.join(full_path, filename))\n",
    "            else:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82eaa038-4838-4b07-921c-059cec306d1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_curated_strings_to_replace(full_path):\n",
    "    \"\"\"get list of strings in codebase that contains 'curated.' (to be later replaced with newer namepsace)\"\"\"\n",
    "    global strings_to_replace\n",
    "    pattern = re.compile(r\"\\bcurated\\.\\b\")\n",
    "    try:\n",
    "        for filename in os.listdir(full_path):\n",
    "            if filename.endswith(\".py\") or filename.endswith(\".sql\"):\n",
    "                with open(os.path.join(full_path, filename), \"r\") as f:\n",
    "                    for line in f:\n",
    "                        for word in line.split():\n",
    "                            if pattern.search(word): \n",
    "                                if (len(word.split(\".\"))) == 2:\n",
    "                                    strings_to_replace.append( re.sub( r'[)\"](.*)', '', (re.sub('[^A-Za-z0-9.]+_', '', word)) ) )\n",
    "                                else:\n",
    "                                    print (f\"This was formatted poorly and is hence not included in the list:\\n {word}\\n\")\n",
    "            elif os.path.isdir(os.path.join(full_path, filename)) and 'Trash' not in filename:\n",
    "                get_curated_strings_to_replace(os.path.join(full_path, filename))\n",
    "            else:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c53e5695-52ac-4549-a708-30e956f0f264",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "strings_to_replace = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377a0139-7496-4264-b4a0-690b3d8f4af0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#iterate through the notebooks and collect list of strings to modify\n",
    "for item in os.listdir(os.path.join(os.getcwd(), 'user_notebooks', 'dev', 'notebooks')):\n",
    "    if '.zip' not in item:\n",
    "        path = os.path.join(os.getcwd(), 'user_notebooks', 'dev', 'notebooks', item)\n",
    "        # print (path)\n",
    "        get_cleansed_strings_to_replace(path)\n",
    "        get_curated_strings_to_replace(path)\n",
    "        get_raw_strings_to_replace(path)\n",
    "        get_semantic_strings_to_replace(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a121b2a-87e0-4046-881e-5be0fc574dbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "strings_to_replace = list(set(strings_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c94c764-898b-4634-914b-3a38b9ccd44f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#create pandas dataframe out of the strings_to_replace\n",
    "df = pd.DataFrame({'current_namespace': strings_to_replace})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba250f49-c6c8-4801-b9aa-c2c3d1b3e7ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def trim_namespace(given_namespace):\n",
    "     return given_namespace.replace('__', '').replace('\"', '').replace(\"'\", '').replace(\"--\", '').replace(\",\", '').replace(\";\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3498f012-eeba-4d12-8481-8cdfb0045f58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def update_namespace(given_namespace):\n",
    "    \"\"\"provide updated UC namespace for a given hive metastore namespace. use provided excel sheet to override the namespace if available.\"\"\"\n",
    "    try:\n",
    "        db = given_namespace.split('.')[0]\n",
    "        table = given_namespace.split('.')[1]\n",
    "        print (db, table)\n",
    "        namespace_elements = get_target_namespace(env, db, table, excel_path='./uc_scope.xlsx')\n",
    "        return f\"{namespace_elements['catalog_name']}.{namespace_elements['database_name']}.{namespace_elements['table_name']}\"\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "def8ce1f-da92-4cac-9d37-0d1d7dfdd191",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#update_namespace('cleansed.sysx_tabley')\n",
    "# will return something like dev_cleansed.sysx.tabley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "947318b9-3c2a-489e-8809-77fef2ab87be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['trimmed_namespace'] = df['current_namespace'].apply(lambda x: trim_namespace(x))\n",
    "df['future_namespace'] = df['trimmed_namespace'].apply(lambda x: update_namespace(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df322ae8-52be-43ed-ba95-fdf90fd7125b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in df.values:\n",
    "    if item[2] != None:\n",
    "        print (f\"Replacing item '{item[1]}' with '{item[2]}'\")\n",
    "        find_replace(f'./user_notebooks/dev/notebooks/', '', item[1], item[2])\n",
    "    # item0 -> current_namespace\n",
    "    # item1 -> trimmed_namespace\n",
    "    # item2 -> future_namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0727c5bf-40e3-4bf7-959d-685cf148abd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once happy with the changes in end user notebooks, push them back into the respective workspace folders by executing push_enduser_files.py. This will push all the updated files back into the workspace user folder (as a zip file). The zip file when received at Databricks workspace, the contents are unzipped. This will also push the original files into a \"backup\" folder."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "end_user_notebooks_code_fix",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
