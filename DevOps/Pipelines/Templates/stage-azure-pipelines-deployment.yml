# ---------------------------------------------------------------------------
# This template is called by azure-platform-deploy-pipeline-cicd.yml
# for each deployment stage.
#
# Pull in and out the different templates that deploy the ARM resources
# needed for your data platform solution. If your solution needs
# a service that is not yet included, build the required ARM template 
# (arm-[service-name-description].json) and step template 
# (step-deploy-arm-[service-name-description].yml). Reference the step template
# below.

parameters:
- name: dependencies
  type: object
  default: ['build']
- name: stage_name
  type: string
- name: variable_template_name
  type: string
- name: run_condition
  type: string
# - name: resource_group
#   type: string

stages:
# ---------------------------------------------------------------------------
# Release to environment
# Only execute if PR into Develop
- stage: ${{ parameters.stage_name }}
  dependsOn: ${{ parameters.dependencies }}
  condition: ${{ parameters.run_condition }}
  variables:
  - template: ../Variables/${{ parameters.variable_template_name }}.yml
  - template: ../Variables/deployable-resources-variables.yml
  jobs:
  # ---------------------------------------------------------------------------
  # Modularise deployment artifacts into separate ARM scripts. Expose these
  # through templates. Introduce or remove templates from this build script
  # as needed for your deployment
  - job: 'deploy_arm'
    steps:
    - download: current
      artifact: arm_templates

    # ------------------------------------------------------------------------
    # Deploy Azure Log related resources
    # ------------------------------------------------------------------------
      # Deploy Log Analytics
    - template: step-deploy-arm-loganalytics.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'  
      condition: eq(${{ variables.loganalytics }}, true)     
      # Deploy BLOB Storage accounts for Data Lake
    - template: step-deploy-arm-logstorage.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
      condition: eq(${{ variables.logstorageaccount }}, true)    

    # ------------------------------------------------------------------------
    # Deploy Azure resources
    # ------------------------------------------------------------------------
    # Deploy Azure SQL DB for Control DB
    - template: step-deploy-arm-azuresql.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
      condition: eq(${{ variables.azuresqlserver }}, true)    
    # Deploy BLOB Storage accounts for Data Lake
    - template: step-deploy-arm-blobstoragev2.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
      condition: eq(${{ variables.azureblobstorage }}, true)    
    # DeployADLS account for Data Lake
    - template: step-deploy-arm-adlsv2.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
      condition: eq(eq(${{ variables.azuredatalakestorage }}, true)   
    # Deploy Databricks Workspace with v-net integration
    - template: step-deploy-arm-databricks-no-vnet-nsg.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
        databricksclustername: ${{ variables.databricksclustername }}
        databricks_driver_node_type_id : ${{ variables.databricksdrivernodetypeid }}
        databricks_node_type_id : ${{ variables.databricksnodetypeid }}
        databricks_spark_version : ${{ variables.sparkClusterVersion }}
        databricks_workers : ${{ variables.databricksworkers }}
        databricks_autotermination : ${{ variables.databricksautotermination }}
      condition: eq(${{ variables.databricksvnet }}, true)    
    # Deploy Databricks Workspace without v-net integration
    - template: step-deploy-arm-databricks-no-vnet-nsg.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
        databricksclustername: ${{ variables.databricksclustername }}
        databricks_driver_node_type_id : ${{ variables.databricksdrivernodetypeid }}
        databricks_node_type_id : ${{ variables.databricksnodetypeid }}
        databricks_spark_version : ${{ variables.sparkClusterVersion }}
        databricks_workers : ${{ variables.databricksworkers }}
        databricks_autotermination : ${{ variables.databricksautotermination }}
      condition: eq(${{ variables.databricksnovnet }}, true)    
    # Deploy Data Factory with access policies for AKV
    - template: step-deploy-arm-datafactory-w-access-policies.yml
      parameters:
        AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
        resource_group: '${{ variables.prefix }}-${{ variables.environment }}'
      condition: eq(${{ variables.datafactory }}, true)    
  # Deploy Control DB schema / DACPAC
  - template: job-deploy-controldb.yml
    parameters:
      AzDoServiceConnection: ${{ variables.azdoresourceconnection }}
    condition: eq(${{ variables.controlschema }} , true)   
