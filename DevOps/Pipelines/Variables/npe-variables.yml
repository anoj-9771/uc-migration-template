variables:
  # Used in service naming
  - name: prefix
    value: ads-v2
  # The default resource group region name
  - name: location
    value: australiaeast
  # environment name used in service naming
  - name: environment
    value: dev
  # Resource group name
  - name: resourcegroupname
    value: ads-v2-dev-rg
  # username for SQL Server Control DB
  - name: azuresqlserverun
    value: sqladmin
  # Name of the service connection in Azure Devops
  - name: azdoresourceconnection
    value: ADS_Demo_SP2
  # The service principal object ID (Not App ID)... Use 'az ad sp show --id <<app-id>> --query "objectId" -o tsv'
  - name: spobjectid
    value: c01fed7c-ab86-4e71-b9cf-0e0c890f45e0
  # Store account type for BLOB Storage e.g. Standard_LRS)
  - name: storageAccountType
    value: Standard_LRS
  # Tagging
  - name: applytags
    value: true
  - name: tags
    value: CostCenter=DataAndAI \
          Environment=NonProduction \
          Owner=jackson.staub@insight.com
  # ------------------------------------------------
  # Service names for environment
  # ------------------------------------------------
  # Name of Azure SQL Server and EDW Database
  - name: azuresqlservername
    value: ${{ lower(variables.prefix) }}-${{ lower(variables.environment) }}-asql
  - name: azureedwdbname
    value: EDW
  # Name of key vault for this environment
  - name: azurekeyvaultname
    value: $(PREFIX)-$(ENVIRONMENT)-AKV
  # Setup secret rotation interval in days
  - name: secretrotationinterval 
    value: 30
  # Name of Log Analytics workspace name
  - name: loganalyticsworkspacename
    value: $(PREFIX)-$(ENVIRONMENT)-ALA
  - name: logstorageaccountname
    value: ${{ replace(lower(variables.prefix),'-','') }}${{ replace(lower(variables.environment),'-','') }}salogs
  # Name of Azure SQL Server and catalog name
  # Data Lake storage account names, commonly split
  # into zones. Ensure it is a comma delimited list
  # as it is split into an array within the ARM 
  # template.
  - name: blobstorageaccountnames
    value: ${{ replace(lower(variables.prefix),'-','') }}${{ replace(lower(variables.environment),'-','') }}saraw, ${{ replace(lower(variables.prefix),'-','') }}${{ replace(lower(variables.environment),'-','') }}sacurated
  - name: datalakestorageaccountnames
    value: ${{ replace(lower(variables.prefix),'-','') }}${{ replace(lower(variables.environment),'-','') }}adls
  # Container or file system names within storage account
  # Used to iterate in ARM template
  - name: logzonename
    value: databricks
  - name: zonenames
    value: raw, curated
    # value: raw, stage, sandbox
  # Databricks workspace name for this enironment
  - name: databricksworkspacename
    value: $(PREFIX)-$(ENVIRONMENT)-ADBWS
  # Data Factory service name for this environment
  - name: datafactoryname
    value: $(PREFIX)-$(ENVIRONMENT)-ADF
  # Data Factory self hosted integrated runtime name
  - name: datafactoryshirname
    value: $(PREFIX)-SHIR
  # Flag to specify whether Data Factory requires Git Integration
  - name: isRepoEnabled
    value: true  
  # ------------------------------------------------
  # Log Analytics related
  # ------------------------------------------------
  - name: loganalyticssku
    value: PerGB2018
  - name: loganalyticsretention
    value: 30  
  # ------------------------------------------------
  # Databricks related
  # ------------------------------------------------
  - name: nsgname
    value: $(PREFIX)-$(ENVIRONMENT)-NSG
  - name: nsgid
    value: 
  - name: vnetresourcegroupname
    value: ads-v2-dev-rg
  - name: vnetName
    value: ads-v2-dev-vnet
  - name: vnetid
    value: 
  - name: publicsubnetcidr
    value: 10.1.2.0/24
  - name: privatesubnetcidr
    value: 10.1.1.0/24
  - name: custompublicsubnetname
    value: databrickspublicsubnet
  - name: customprivatesubnetname
    value: databricksprivatesubnet
  - name: databrickspricingtier
    value: premium
  - name: databricksclustername
    value: etl-cluster
  - name: sparkClusterVersion
    value: 7.0.x-scala2.12
  - name: databricksdrivernodetypeid
    value: Standard_D3_v2
  - name: databricksnodetypeid
    value: Standard_F4s
  - name: databricksworkers
    value: 2
  - name: databricksautotermination
    value: 10